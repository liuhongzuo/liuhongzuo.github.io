下面整理目前主流的 文本/多模态 embedding 模型（以及相关类别），各自的优缺点，以及适合的使用场景。需要看你是偏“语义检索／RAG（Retrieval-Augmented Generation）”、对话、推荐系统、分类、知识图谱、跨语言／跨模态等方向，我也可以帮你对比更适合你的模型。


---

Embedding 模型的分类

从大体上看，可以按以下维度分类：

分类	代表模型 / 类型	特点

静态词向量 (Static Word Embeddings)	Word2Vec, GloVe, FastText	每个单词一个向量，不考虑上下文；FastText 支持 subword，可以缓解罕见词／未登录词问题。
上下文词嵌入 (Contextual Word / Token Embedding)	BERT / RoBERTa / ELMo 等	同一个词在不同上下文中表示不同；更好捕捉语义歧义；基础于 Transformer 模型。
句子／段落／文档级的 bi-encoder/sentence embedding 模型	Sentence-BERT, E5, Universal Sentence Encoder, Cohere Embed 等	将句子／段落直接映射为一个向量；设计用于近义句，文档检索，RAG 等任务；比词级／Token-level 模型检索效率好。
大语言模型 (LLM) 作 embedding	用 GPT／LLaMA 等模型 via prompt 或微调得到 embedding（直接输出 vector 或提取某些 layer 的 hidden states）	通常模型更大，能捕捉更丰富语义 & 指令/任务信息，但成本（计算 + 延迟 + 内存）也高。
指令调优／对比学习调优的 embedding 模型	E5（含 multilingual 或 domain-specific 版本）等；也包括那些专门为检索任务以对比 loss（contrastive learning）训练的模型	在检索任务上性能通常比通用模型好；更容易对特定领域或语言调优。
稀疏 vs 密集 embedding	稀疏 embedding（比如倒排索引 + BM25 + 稀疏向量结合） vs 密集 embedding（向量相似度检索）	稀疏搜索在某些情况下（尤其关键词、长尾概念）表现好，密集搜索在语义匹配上更强。
跨语言／多语言 embedding	multilingual E5, LaBSE, etc.	支持多种语言，对跨语言检索／翻译等任务有用。
跨模态 embedding	CLIP（图像＋文本），ALIGN，Flamingo, 等	用于图像 + 文本联合表示／检索，或者视频、音频与文本或图像联合任务。



---

各种模型／类型的优缺点

下面是一些主流类型或具体模型的对比（不 exhaustive，但覆盖“现阶段经常被选用”的）：

模型 / 类型	优点	缺点	适合场景

Word2Vec / GloVe	轻量、训练快、资源消耗低；在需要处理非常大规模语料或快速实现关键词推荐任务时还算好；FastText 尤其对未登录词／子词敏感性较好。	不考虑上下文；歧义词处理差；句子／段落级别语义匹配效果较差；不能直接用于句子级相似性度量。	较老的系统；关键词检索；需要非常高吞吐量但语义深度要求不高；资源受限 或 “作为 baseline”。
上下文词嵌入 (BERT, RoBERTa etc.)	能处理上下文歧义；对短句子或问答中的词义区分好；可微调适配具体任务；支持句子内部的语义理解非常好。	如果要做句子／文档级检索，单用 token embedding + pooling 开销大；BERT full 模型在部署中的延迟和计算成本高；如果没微调，其 embedding 不一定为检索任务最优。	问答系统中理解上下文需要；分类任务；需要精细语义判别；对词义歧义敏感的应用。
Sentence / 文档级 Bi-encoder 模型 (SBERT, E5, Cohere, etc.)	对句子／段落／文档检索效果强；速度快（比 cross-encoder 之类 reranker 或 BERT 上下文内匹配快）；向量尺寸与 recall /精度之间一般有较好折中；适合 RAG。	可能忽略更细粒度的交互特征（某些语义关系在 cross-encoder 中才能很好捕捉）；对长文档需要 chunk 或摘要处理；模型体积／推理资源也可能不小；对于某些任务可能需要额外微调。	文档检索／问答；RAG；对话检索；信息检索客户支持；FAQ 匹配；推荐系统中的语义匹配。
LLM‐based Embeddings（大模型 + prompt /指令调优）	理解能力更强，可以编码复杂语义、世界知识、推理；指令调优后，在多任务／跨任务场景中表现优；可能在跨语言／长上下文的情况下优于小模型。	成本高（推理时间、硬件需求、内存消耗都大）；延迟可能不符合实时系统要求；如果 prompt 设计／抽取策略不好也可能浪费性能；可控性差；在规模上部署可能困难。	高精度搜索；复杂问答；跨语言场景；法律、医学等领域需要强语义 + 专业知识；要处理长上下文；或者在离线批量任务。
指令调优 / 对比学习训练过的专门检索模型（如 E5, multilingual-E5, domain-specific embedding 模型）	在检索任务上通常效果最好；多语言／领域适配性强；在基准中往往领先；对比学习使语义结构更加明确；可能有较高的 recall/p@k/nDCG 等指标。	通常需要较多标注／近似标注数据；如果领域差异大，需要重新微调；大模型 + 对比 loss 在部署中资源成本也较高；embedding 的维度可能大；存储 +索引成本不低。	专业检索系统；多语言检索；行业知识库；需要高 recall & 高精度的时候；希望检索结果的语义匹配度高。
稀疏 + 混合检索 (sparse + dense hybrids)	可以结合关键词优势（稀疏）与语义匹配优势（密集）；对于概念/实体匹配或者长尾／罕见词可能更好；有些系统可以首先用 sparse 或 BM25 做粗检索，再 densese embed/rerank，效能好。	实现复杂度高；需要维护多个索引；参数调优／融合策略复杂；对硬件／存储要求更多；可能引入延迟。	大规模文档库；内容多样且涵盖专业／长尾词汇的领域；当纯 dense 或纯 sparse 的效果不能满足时；在检索系统中追求综合性能。
跨语言／多语言 embedding 模型	支持多语言检索；对于跨语言问答／翻译／国际化产品很关键；可以减少为每个语言单独训练模型的工作量。	在某些语言上性能可能弱（语料欠缺）；模型尺寸通常大；跨语言语义不对齐的问题；可能在特定语言／领域上的表现不如专门训练的母语模型。	国际化应用；多语言用户；翻译系统；跨语言文档检索／比较；全球产品。
跨模态 embedding（文本＋图像／视频／音频等）	可以做文本-图像检索、图片标注、视觉问答等；在处理多媒体内容时优势明显；可用于生成多模态提示／理解多模态内容。	模型更复杂；训练数据要求高；不同模态对齐问题（文本 vs 图像 vs 视频）较难；存储计算成本更高；可能延迟较大；在某些任务中图像内容的噪声／不一致性问题。	图像＋文本检索；社交媒体内容理解；电商（商品图片＋描述）；视频字幕检索；视觉问答／多模态生成任务。



---

新趋势 & Benchmark 指标／经验教训

从最近的一些调研／文章里，有以下几点趋势与注意事项：

指令调优（instruction-tuning） + 对比学习（contrastive pre-training）结合起来，能让 embedding 更通用、表现稳定。

多语言／跨语言模型越来越普遍，对支持低资源语言与全球产品很重要。

模型输入的最大 token 长度、chunking（将文档切分为若干块）策略，对长文档检索／RAG 情况影响极大。合适的 chunk 大小、滑动窗口策略等需要调优。

性能 vs 成本（延迟、存储、计算）的 trade-off 非常关键。一个大模型在基准上看起来不错，但如果实际查询／部署要求响应快、资源有限，就可能不合适。

在某些专业领域（医学、法律、金融等），通用 embedding 模型可能会忽略特定术语、规范或隐含知识，需要做领域微调或使用 domain-specific 模型。



---

示例：几款具体模型对比

下面是几个具体模型 + 适合场景简评（截至 2025 年中期／最新发表资料）：

模型	优势亮点	劣势或限制	最合适使用场景

E5（一般版 + multilingual / domain-specific）	在多种语言 + 多种检索任务上表现很好；常被 benchmark 拉到前列；密集检索任务中性价比高。	对非常长文本可能需要 chunk；对于非常专的术语／专业语料可能未覆盖；部署成本（算力 +存储）仍不低。	大型文档检索系统；国际化产品；RAG 系统作为 main embedder；Web 搜索／知识库搜索。
Sentence-BERT（SBERT）	社区成熟；支持多种语言／模型变体；有丰富资源；延迟 / 推理成本中等；在句子／短段落匹配上效果很好。	对于非常长文章不能直接用一个 embedding；如果没有在目标领域训练，可能对领域术语／风格敏感性较差；比最新大型对比学习模型可能略差。	FAQ 匹配；问答系统短问句；分类器特征；中等规模检索；原型搭建期。
LLM＋Prompt 或 LLM 微调得到的 embedding	更强的语义理解；可能带有任务／指令信息；能处理复杂查询；在推理、上下文敏感性上有优势。	成本高；延迟大；规模部署难；可能在批量检索／实时系统中不经济；如果 prompt 或提取方式不佳可能效果不稳定。	高端问答系统；多轮对话 + 推理场景；需要跨语言或长上下文支持；医学／法律／科研等专业场景；或者作为 reranker／后处理环节。
混合稀疏 + 密集检索系统	利用关键词 + 语义双重优势；对长尾词 / 专有名词 /实体匹配好；可以用 sparse 提高 recall + dense 提高语义覆盖；整体效果稳。	架构复杂；维护索引 + 两类系统；调参多；可能 latency 较高；存储成本 +资源成本双重。	大型文档库；内容专业且包括大量实体名称／行业术语；当用户查询既包含关键词又隐含语义的时候；希望提升 recall + precision 平衡。
跨模态模型（如 CLIP 等）	文本 + 图像联合理解 +检索；在视觉内容丰富的应用中非常有价值；可以做图像检索／图像标注／视觉问答等任务。	若对齐质量或图像质量差，噪声大；训练／推理资源消耗高；部署与数据准备难度大；文本/图像模态之间不一致性问题。	电商商品搭配检索；社交媒体内容分析；图像标注 / 自动 caption；图像 + 文本检索；视觉问答；广告推荐中图像加文本特征。



---

如果要选模型：一些建议

根据你具体的需求／场景，可以考虑以下选项：

问自己这些问题：

1. 文本长度／文档大小大致是多少？是否需要支持很长的上下文？


2. 是否需要多语言支持？你主要是中文、英文还是多种语言混用？


3. 精度 vs 速度 vs 成本（硬件／延迟）哪个更重要？


4. 是否有领域特定的术语／知识？是否准备做领域微调？


5. 实时性要求／批处理／离线使用？


6. 有没有标注或近似标注数据，可以用于微调或对比学习调优？



实践中常用路径：

1. 用一个比较轻量的通用 sentence embedding 作 baseline（比如 SBERT / miniLM / E5 小版本等）。


2. 在你的实际文档 /查询上做性能评估（例如用 MTEB 或你自己的小样本，比较 recall@k / nDCG /
