import onnxruntime as ort
import scipy.io.wavfile as wav
import numpy as np
import json

def run_inference(model_path, config_path, inputs, output_wav_path="output.wav"):
    """
    Args:
        model_path: .onnx 模型路径
        config_path: .json 配置文件路径 (用于读取采样率)
        inputs: 你已经准备好的输入字典 (包含 input, input_lengths, scales 等)
        output_wav_path: 输出文件名
    """
    
    # 1. 获取采样率 (Sample Rate)
    # Piper 的采样率通常是 22050Hz，但也可能是 16000Hz，必须从 config 读取
    with open(config_path, 'r', encoding='utf-8') as f:
        config = json.load(f)
        # 不同的 config 格式可能略有不同，通常在 audio -> sample_rate
        sample_rate = config.get("audio", {}).get("sample_rate", 22050)
        print(f"检测到采样率: {sample_rate} Hz")

    # 2. 加载 ONNX 模型
    print("正在加载模型...")
    sess = ort.InferenceSession(model_path)

    # 3. 运行推理 (Run Inference)
    # sess.run(output_names, input_feed)
    # output_names=None 表示获取所有输出
    print("正在运行推理...")
    outputs = sess.run(None, inputs)
    
    # 4. 获取音频数据
    # Piper 的输出通常是一个列表，第一个元素是音频
    # 输出形状通常是 (Batch_Size, Num_Samples)，例如 (1, 80000)
    audio = outputs[0]
    
    # 5. 数据后处理
    # 移除 Batch 维度: (1, N) -> (N,)
    audio = audio.squeeze()
    
    # 注意：Piper 输出通常是 float32 类型，范围在 -1.0 到 1.0 之间
    # scipy.io.wavfile.write 支持 float32，但必须确保数据在 [-1, 1] 之间
    # 也可以选择转为 int16 (标准 16-bit 音频) 以兼容更多播放器
    
    # 转换为 16-bit PCM 格式 (推荐，兼容性最好)
    audio_int16 = (audio * 32767).clip(-32768, 32767).astype(np.int16)

    # 6. 保存为 WAV 文件
    wav.write(output_wav_path, sample_rate, audio_int16)
    print(f"✅ 音频已保存至: {output_wav_path}")

# --- 使用示例 ---
if __name__ == "__main__":
    # 假设这是你已经准备好的输入张量 (复用之前的逻辑)
    # 这里仅做演示，实际上你应该传入你生成的 inputs 变量
    # ---------------------------------------------------------
    # 模拟数据 (请替换为你真实的数据!)
    dummy_input = np.array([[1, 0, 10, 0, 20, 0, 2]], dtype=np.int64)
    dummy_len = np.array([7], dtype=np.int64)
    dummy_scales = np.array([0.667, 1.0, 0.8], dtype=np.float32)
    
    inputs = {
        "input": dummy_input,
        "input_lengths": dummy_len,
        "scales": dummy_scales
    }
    # ---------------------------------------------------------

    model_file = "en_US-lessac-medium.onnx"
    config_file = "en_US-lessac-medium.onnx.json"
    
    try:
        run_inference(model_file, config_file, inputs, "result.wav")
    except Exception as e:
        print(f"发生错误: {e}")
