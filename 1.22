import json
import numpy as np
import piper_phonemize

class PiperPreprocessor:
    def __init__(self, config_path):
        with open(config_path, 'r', encoding='utf-8') as f:
            self.config = json.load(f)
        
        self.phoneme_id_map = self.config['phoneme_id_map']
        self.espeak_voice = self.config['espeak']['voice']
        
        self.pad_id = self.phoneme_id_map.get('_', [0])[0]
        self.bos_id = self.phoneme_id_map.get('^', [1])[0]
        self.eos_id = self.phoneme_id_map.get('$', [2])[0]

    def intersperse(self, lst, item):
        if not lst: return []
        result = [item] * (len(lst) * 2 - 1)
        result[0::2] = lst
        return result

    def get_phonemes_batch(self, text):
        """
        核心修改：直接返回 piper-phonemize 的原始结果 (list of lists)
        例如: [['H', 'e', 'l', 'l', 'o'], ['W', 'o', 'r', 'l', 'd']]
        """
        return piper_phonemize.phonemize_espeak(text, self.espeak_voice)

    def sequence_to_tensor_dict(self, phoneme_ids, speaker_id=0):
        """将单个句子的音素ID转为Tensor字典"""
        # 1. 插入 Pad (Intersperse)
        interspersed = self.intersperse(phoneme_ids, self.pad_id)
        
        # 2. 全包裹 Pad (BOS + Pad + ... + Pad + EOS)
        sequence = (
            [self.bos_id] + 
            [self.pad_id] + 
            interspersed + 
            [self.pad_id] + 
            [self.eos_id]
        )

        # 3. 构建 Tensor
        input_tensor = np.array([sequence], dtype=np.int64)
        input_lengths = np.array([len(sequence)], dtype=np.int64)
        scales = np.array([0.667, 1.0, 0.8], dtype=np.float32)

        inputs = {
            "input": input_tensor,
            "input_lengths": input_lengths,
            "scales": scales
        }
        
        if self.config.get('num_speakers', 1) > 1:
            inputs["sid"] = np.array([speaker_id], dtype=np.int64)
            
        return inputs

    def process_text(self, text, speaker_id=0):
        """
        主入口：输入整段文本，返回一个生成器(Generator)或列表。
        每个元素对应一个句子的 Tensor 输入字典。
        """
        # 1. 获取分句后的音素列表 (List of Lists)
        sentences_phonemes = self.get_phonemes_batch(text)
        
        results = []
        for sentence_p in sentences_phonemes:
            # 2. 音素转 ID
            ids = []
            for p in sentence_p:
                if p in self.phoneme_id_map:
                    ids.extend(self.phoneme_id_map[p])
            
            # 3. 只有当句子有内容时才处理
            if ids:
                tensor_dict = self.sequence_to_tensor_dict(ids, speaker_id)
                results.append(tensor_dict)
                
        return results

# --- 模拟运行 ---
if __name__ == "__main__":
    # 模拟 Config
    config_path = "en_US-lessac-medium.onnx.json"
    
    try:
        preprocessor = PiperPreprocessor(config_path)
        
        # 输入一段长文本（包含两个句子）
        long_text = "Hello world. This is the second sentence."
        
        # 获取所有句子的 Tensor 输入
        tensor_inputs_list = preprocessor.process_text(long_text)
        
        print(f"检测到 {len(tensor_inputs_list)} 个句子，准备分别送入模型...\n")
        
        import onnxruntime as ort
        # model_path = "en_US-lessac-medium.onnx"
        # sess = ort.InferenceSession(model_path)
        
        audio_pieces = []
        
        for i, inputs in enumerate(tensor_inputs_list):
            print(f"--- 处理第 {i+1} 句 ---")
            print(f"Input Shape: {inputs['input'].shape}")
            
            # 在这里运行推理
            # audio = sess.run(None, inputs)[0]
            # audio_pieces.append(audio)
            
        print("\n处理完成。后续步骤：将 audio_pieces 拼接，并建议在中间插入少量静音数据。")

    except Exception as e:
        print(f"Error: {e}")
