#pragma once
#include "core/framework/execution_provider.h"

namespace onnxruntime {

// 继承 IExecutionProvider
class VirtualExecutionProvider : public IExecutionProvider {
 public:
  explicit VirtualExecutionProvider(const VirtualExecutionProviderInfo& info)
      : IExecutionProvider{onnxruntime::kVirtualExecutionProvider} { // 定义你的 EP 类型名称
    
    // 初始化你的 Device 分配器（如果是真实硬件，这里要分配 Device 内存）
    // 这里我们只是模拟，复用 CPU 分配器
    AllocatorCreationInfo default_memory_info(
        [](int) { return std::make_unique<CPUAllocator>(); },
        0, true);
    InsertAllocator(CreateAllocator(default_memory_info));
  }

  // 核心函数 1: 告诉 ORT 你支持哪些节点
  std::vector<std::unique_ptr<ComputeCapability>> 
  GetCapability(const onnxruntime::GraphViewer& graph_viewer,
                const IKernelLookup& /*kernel_lookup*/) const override;

  // 核心函数 2: 提供你的 Kernel 实现注册表
  std::shared_ptr<KernelRegistry> GetKernelRegistry() const override;
};
} // namespace onnxruntime

#include "virtual_execution_provider.h"

namespace onnxruntime {

std::vector<std::unique_ptr<ComputeCapability>> 
VirtualExecutionProvider::GetCapability(const onnxruntime::GraphViewer& graph_viewer,
                                        const IKernelLookup& /*kernel_lookup*/) const {
  std::vector<std::unique_ptr<ComputeCapability>> result;

  // 遍历图中所有节点
  for (const auto& node : graph_viewer.Nodes()) {
    // 假设我们的 VirtualEP 只支持 "Add" 算子
    if (node.OpType() == "Add") {
      
      // 创建一个 ComputeCapability
      std::unique_ptr<ComputeCapability> cc = std::make_unique<ComputeCapability>();
      
      // 定义这是一个单一节点执行 (如果是编译器后端，可能会把多个节点融合成一个子图)
      cc->sub_graph = nullptr; 
      cc->nodes_to_optimize.push_back(node.Index());
      
      // 声明这个能力属于 VirtualEP
      cc->type = "VirtualExecutionProvider";
      
      result.push_back(std::move(cc));
    }
  }
  return result;
}
}


